{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import os\n",
    "import data_readin\n",
    "import single_source_algo as ssa\n",
    "import lmvc_algo as lmvc\n",
    "import cbsnmf_algo as cbsnmf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import LP_solver as solver\n",
    "import xlsxwriter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the total distance of a cluster under clique-based formulation\n",
    "def cost_calculator(cluster, dic):\n",
    "    cost = 0\n",
    "    q = len(cluster)\n",
    "    n = len(cluster[0])\n",
    "    reshaped_cluster = cluster.T.reshape(cluster.shape[0]*cluster.shape[1])\n",
    "    \n",
    "    for i in range(q):\n",
    "        sub_cluster = np.array(np.where(reshaped_cluster==i))[0]\n",
    "        sub_cluster = np.array([sub_cluster[j]-j*q for j in range(n)])\n",
    "        for i in range(len(sub_cluster)): # number of views\n",
    "            for j in range(i+1, len(sub_cluster)):\n",
    "                cost += dic[(i+1, j+1)][int(sub_cluster[i])][int(sub_cluster[j])]\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test all the single-source methods at the same time.\n",
    "# User may alter inputs for all single-source methods:\n",
    "#    num_views -> number of sensors/stages\n",
    "#    num_targets -> number of targets\n",
    "#    num_generated -> number of data sources (further used in multi-source section)\n",
    "#    filePath -> relative path for input data\n",
    "#             -> 'dist_data/'        : refers to data with all uniform distributions with scale 0-100.\n",
    "#             -> 'poisson_dist_1/'   : refers to data with all 4 sources of uniform distributions with scale \n",
    "#                                      0-100, and 1 source of poisson distribution with mean = 50\n",
    "#             -> 'uniform_dist_1/'   : refers to data with all 4 sources of uniform distributions with scale \n",
    "#                                      0-100, and 1 source of uniform distributions with scale 0-10.\n",
    "#             -> 'uniform_dist_2/'   : refers to data with all 3 sources of uniform distributions with scale \n",
    "#                                      0-100, and 2 source of uniform distributions with scale 0-10.\n",
    "#             -> 'further_test_dist/': refers to data with all niform distributions with scale 0-100 with \n",
    "#                                      relatively large dimensions (over 30 sensors/stages, 30 targets).\n",
    "# Output: single-source clustering information.\n",
    "# Note: \n",
    "#    Under medium dimensions (10 sensors/stages, 20targets), LP will face computational difficulties.\n",
    "#    Under large dimensions (over 30 sensors/stages, 30 targets), LP will not be able to \n",
    "#    solve in a reasonable time, and RMSRA will take longer time to solve. \n",
    "#    Please comment out the LP section in the function for large dimensions.\n",
    "def test_single_source(num_views, num_targets, num_generated):\n",
    "    test_output_clu_dict = {}\n",
    "\n",
    "    forward_time = 0\n",
    "    rmsra_time = 0\n",
    "    lp_time = 0\n",
    "\n",
    "    forward_cost = 0\n",
    "    rmsra_cost = 0\n",
    "    lp_cost = 0\n",
    "\n",
    "    for i in range(num_generated):\n",
    "        index = i + 1\n",
    "        filePath = 'dist_data/'\n",
    "        #filePath = 'uniform_dist_1/'\n",
    "        #filePath = 'uniform_dist_2/'\n",
    "        #filePath = 'poisson_dist_1/'\n",
    "        #filePath = 'further_test_dist/'\n",
    "        fileName = str(num_views) + 'D' + str(num_targets) + '-' + str(index) + '.dat'\n",
    "        completeFileName = os.path.join(filePath, fileName)\n",
    "        num_targets, num_views, raw_data_dict = data_readin.data_readin(completeFileName)\n",
    "\n",
    "        time_one_start = time.time()\n",
    "\n",
    "        # FHA\n",
    "        test_forward_clu, total_cost = ssa.forward_process(raw_data_dict, num_targets, num_views)\n",
    "        forward_time += time.time()-time_one_start\n",
    "        temp = cost_calculator(test_forward_clu, raw_data_dict)\n",
    "        forward_cost += temp\n",
    "\n",
    "        # RMSRA\n",
    "        test_output_clu = ssa.RMSRA(raw_data_dict, num_targets, num_views)\n",
    "        test_output_clu = test_output_clu.astype(int)\n",
    "        test_output_clu_dict[i] = test_output_clu\n",
    "\n",
    "        temp = cost_calculator(test_output_clu, raw_data_dict)\n",
    "        rmsra_cost += temp\n",
    "        rmsra_time += time.time() - time_one_start\n",
    "        \n",
    "        # LP\n",
    "        time_comparison_start = time.time()\n",
    "        lps = solver.LP_Solution(num_views, num_targets, raw_data_dict)\n",
    "        m = lps.solver()\n",
    "        lp_time += time.time() - time_comparison_start\n",
    "        lp_cluster = lps.getPath(m)\n",
    "        lp_cost += cost_calculator(lp_cluster, raw_data_dict)\n",
    "\n",
    "\n",
    "    print(\"The RHA clique-based cost is:\", forward_cost / num_generated)\n",
    "    print(\"The RMSRA clique-based cost is:\", rmsra_cost / num_generated)\n",
    "    print(\"The LP clique-based cost is:\", lp_cost / num_generated)\n",
    "\n",
    "    print('\\nFHA time cost %.5f s' % (forward_time / num_generated))\n",
    "    print('RMSRA time cost %.5f s' % (rmsra_time / num_generated))\n",
    "    print('LP time cost %.5f s' % (lp_time / num_generated))\n",
    "    \n",
    "    return test_output_clu_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test all the LMVC algorithm.\n",
    "# User may alter inputs for LMVC algorithm:\n",
    "#    num_views -> number of sensors/stages\n",
    "#    num_targets -> number of targets\n",
    "#    num_generated -> number of data sources\n",
    "#    test_output_clu_dict -> single-source clustering information\n",
    "#    filePath -> relative path for input data (Please refer to the test_single_source() description)\n",
    "# Note:\n",
    "#    All the input information should match with the outputs of the single-source methods. \n",
    "def test_LMVC(test_output_clu_dict, num_views, num_targets, num_generated):\n",
    "    lmvc_time = 0\n",
    "    lmvc_input_dict = {}\n",
    "\n",
    "    for i in range(num_generated): \n",
    "        lmvc_input = np.ones((num_targets, num_views))\n",
    "        for p in range(num_targets):\n",
    "            for q in range(num_targets):\n",
    "                for r in range(num_views):\n",
    "                    if test_output_clu_dict[i][q][r] == p:\n",
    "                        lmvc_input[p][r] = q\n",
    "        lmvc_input = lmvc_input.astype(int)\n",
    "        lmvc_input_dict[i] = lmvc_input\n",
    "\n",
    "    lmvc_start = time.time()\n",
    "\n",
    "    lmvc_results = []\n",
    "    lmvc_cost = 0\n",
    "    cross_domain_source = lmvc.Data(num_views, num_targets, lmvc_input_dict)\n",
    "    cluster = cross_domain_source.process()\n",
    "    cluster = np.array(cluster)\n",
    "    cluster_rev = np.ones([num_targets, num_views])\n",
    "    for p in range(len(cluster_rev)):\n",
    "        for q in range(len(cluster_rev[0])):\n",
    "            row_num = cluster[p][q]\n",
    "            col_num = q\n",
    "            cluster_rev[row_num,col_num] = p\n",
    "    cluster_rev = cluster_rev.astype(int)\n",
    "\n",
    "    lmvc_time += time.time() - lmvc_start\n",
    "\n",
    "    for i in range(num_generated):\n",
    "        index = i + 1\n",
    "        filePath = 'dist_data/'\n",
    "        #filePath = 'uniform_dist_1/'\n",
    "        #filePath = 'uniform_dist_2/'\n",
    "        #filePath = 'poisson_dist_1/'\n",
    "        #filePath = 'further_test_dist/'\n",
    "        fileName = str(num_views) + 'D' + str(num_targets) + '-' + str(index) + '.dat'\n",
    "        completeFileName = os.path.join(filePath, fileName)\n",
    "        num_targets, num_views, raw_data_dict = data_readin.data_readin(completeFileName)\n",
    "\n",
    "        lmvc_cost += cost_calculator(cluster_rev, raw_data_dict)\n",
    "    lmvc_results.append(lmvc_cost/num_generated)\n",
    "\n",
    "    print(\"\\nThe LMVC clique-based cost  is:\", np.mean(lmvc_results))\n",
    "    print('LMVC time cost %.5f s' % (lmvc_time))\n",
    "    \n",
    "    return cluster_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test all the CBSNMF algorithm.\n",
    "# User may alter inputs for CBSNMF algorithm:\n",
    "#    num_views -> number of sensors/stages\n",
    "#    num_targets -> number of targets\n",
    "#    num_generated -> number of data sources\n",
    "#    test_output_clu_dict -> single-source clustering information\n",
    "#    filePath -> relative path for input data (Please refer to the test_single_source() description)\n",
    "#    connected_reg -> penality factor for targets clustered in the same group\n",
    "#    unconeected_reg -> penality factor for targets not clustered in the same group\n",
    "#    alpha -> coefficient for the regularization matrix\n",
    "#    max_iter -> maximum iteration for cbsnmf\n",
    "# Note:\n",
    "#    Input information should match with the outputs of the single-source methods. \n",
    "def test_cbsnmf(test_output_clu_dict, num_views, num_targets, num_generated):\n",
    "    connected_reg = 0.1\n",
    "    unconeected_reg = 100\n",
    "    test_alphas = [1e-10,1e-9,1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2, 1e-1, 1, 10, 100, 1000]\n",
    "    max_iter =1000\n",
    "        \n",
    "    test_cbsnmf = []\n",
    "    test_cbsnmf_times = []\n",
    "    test_cbsnmf_results = []\n",
    "    test_alpha = []\n",
    "    for a in test_alphas:\n",
    "        test_cbsnmf_costs = []\n",
    "        cbsnmf_results = []\n",
    "        for k in range(5):\n",
    "            cbsnmf_cost = 0\n",
    "            cbsnmf_time = 0\n",
    "            cbsnmf_time_start = time.time()    \n",
    "\n",
    "            # choose the types of similarity matrix\n",
    "            #indicator_matrix = cbsnmf.get_norm_indicator_matrix(test_output_clu_dict, num_targets, num_views, num_generated)\n",
    "            indicator_matrix = cbsnmf.get_scale_indicator_matrix(test_output_clu_dict, num_targets, num_views)\n",
    "            #indicator_matrix = cbsnmf.density_indicator_matrix(test_output_clu_dict, num_targets, num_views, num_generated)\n",
    "\n",
    "            # choose the tyoe of regularization matrix\n",
    "            #g = cbsnmf.get_reg_matrix(indicator_matrix, connected_reg, unconeected_reg)\n",
    "            g = cbsnmf.get_scale_reg_matrix(test_output_clu_dict, num_targets, num_views)\n",
    "\n",
    "            u = cbsnmf.matrix_fact(indicator_matrix, g, a, max_iter, num_targets, num_views)\n",
    "            cbsnmf_result = cbsnmf.get_concensus_matrix(u, num_targets, num_views)\n",
    "            cbsnmf_results.append(cbsnmf_result)\n",
    "\n",
    "            cbsnmf_time += time.time() - cbsnmf_time_start\n",
    "\n",
    "            for i in range(num_generated):\n",
    "                index = i + 1\n",
    "                filePath = 'dist_data/'\n",
    "                #filePath = 'uniform_dist_1/'\n",
    "                #filePath = 'uniform_dist_2/'\n",
    "                #filePath = 'poisson_dist_1/'\n",
    "                #filePath = 'further_test_dist/'\n",
    "                fileName = str(num_views) + 'D' + str(num_targets) + '-' + str(index) + '.dat'\n",
    "                completeFileName = os.path.join(filePath, fileName)\n",
    "                num_targets, num_views, raw_data_dict = data_readin.data_readin(completeFileName)\n",
    "\n",
    "                cbsnmf_cost += cost_calculator(cbsnmf_result, raw_data_dict)\n",
    "        \n",
    "            test_cbsnmf_costs.append(cbsnmf_cost/num_generated)\n",
    "        test_cbsnmf_times.append(cbsnmf_time/5)\n",
    "        test_cbsnmf_results.append(cbsnmf_results[test_cbsnmf_costs.index(min(test_cbsnmf_costs))])\n",
    "        test_cbsnmf.append(min(test_cbsnmf_costs))\n",
    "        test_alpha.append(a)\n",
    "\n",
    "    output_cbsnmf_cost = min(test_cbsnmf)\n",
    "    output_cbsnmf_result = test_cbsnmf_results[test_cbsnmf.index(min(test_cbsnmf))]\n",
    "    output_cbsnmf_alpha = test_alpha[test_cbsnmf.index(min(test_cbsnmf))]\n",
    "    output_cbsnmf_time = test_cbsnmf_times[test_cbsnmf.index(min(test_cbsnmf))]\n",
    "    print(\"\\nThe CBSNMF clique-based cost  is:\", output_cbsnmf_cost)\n",
    "    print('The alpha of CBSNMF is: ', output_cbsnmf_alpha)\n",
    "    print('The CBSNMF time cost %.5f s' % output_cbsnmf_time)\n",
    "    \n",
    "    return output_cbsnmf_result.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RHA clique-based cost is: 586.0\n",
      "The RMSRA clique-based cost is: 572.8\n",
      "The LP clique-based cost is: 571.6\n",
      "\n",
      "FHA time cost 0.00157 s\n",
      "RMSRA time cost 0.01040 s\n",
      "LP time cost 0.33213 s\n",
      "\n",
      "The CBSNMF clique-based cost  is: 1625.2\n",
      "The alpha of CBSNMF is:  1e-06\n",
      "The CBSNMF time cost 0.02373 s\n",
      "[[ 8  2 17]\n",
      " [12  6  1]\n",
      " [ 5 12  7]\n",
      " [ 0  8 12]\n",
      " [ 1 13 16]\n",
      " [16 18 19]\n",
      " [ 4 16  2]\n",
      " [ 2 11  3]\n",
      " [10  7  5]\n",
      " [ 9  0 18]\n",
      " [ 7 14 14]\n",
      " [14  1 15]\n",
      " [ 3  9  8]\n",
      " [ 6  3 10]\n",
      " [15 17 11]\n",
      " [11  4  0]\n",
      " [17 10  9]\n",
      " [13 15 13]\n",
      " [19  5  6]\n",
      " [18 19  4]]\n",
      "\n",
      "The LMVC clique-based cost  is: 1845.6\n",
      "LMVC time cost 0.04994 s\n",
      "[[ 0  7 14]\n",
      " [ 1 14  5]\n",
      " [ 2  4 15]\n",
      " [ 3  0 12]\n",
      " [ 4  5  9]\n",
      " [ 5 19  0]\n",
      " [ 6 11 10]\n",
      " [ 7  1 18]\n",
      " [ 8 17 16]\n",
      " [ 9 10 19]\n",
      " [10 15 11]\n",
      " [11  9 17]\n",
      " [12  6  2]\n",
      " [13 12  8]\n",
      " [14  3  1]\n",
      " [15  2  4]\n",
      " [16  8  3]\n",
      " [17 13  6]\n",
      " [18 16  7]\n",
      " [19 18 13]]\n"
     ]
    }
   ],
   "source": [
    "# Testing for all the methods and algorithms.\n",
    "# User may alter inputs for methods and algorithms:\n",
    "#    num_views -> number of sensors/stages\n",
    "#    num_targets -> number of targets\n",
    "#    num_generated -> number of data sources\n",
    "def main():\n",
    "    num_views = 3\n",
    "    num_targets = 20\n",
    "    num_generated = 5\n",
    "    test_output_clu_dict = test_single_source(num_views, num_targets, num_generated)\n",
    "    \n",
    "    output_clu = test_cbsnmf(test_output_clu_dict, num_views, num_targets, num_generated)\n",
    "    print(output_clu)\n",
    "    \n",
    "    output_clu = test_LMVC(test_output_clu_dict, num_views, num_targets, num_generated)\n",
    "    print(output_clu)\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
