{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import os\n",
    "import data_readin\n",
    "import single_source_algo as ssa\n",
    "import lmvc_algo as lmvc\n",
    "import cbsnmf_algo as cbsnmf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import LP_solver as solver\n",
    "import xlsxwriter\n",
    "import itertools\n",
    "from numpy import random\n",
    "import LP_solver as solver\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perfrom hungarian algorithm for the 2D assignment problem \n",
    "# dist_matrix: input distance matrix\n",
    "# num_targets: number of targets\n",
    "# x_clean: solution for the 2D assignment problem\n",
    "# total_cost: total cost for the 2D assignment problem solution\n",
    "def assignment_problem(dist_matrix, num_targets):\n",
    "    row_ind, col_ind = linear_sum_assignment(dist_matrix)\n",
    "\n",
    "    total_cost = 0\n",
    "    x_clean = np.zeros((num_targets, num_targets))\n",
    "    for i in range(num_targets):\n",
    "        x_clean[i, col_ind[i]] = 1\n",
    "        total_cost = total_cost + dist_matrix[i][col_ind[i]]\n",
    "    return x_clean, total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the total distance of a cluster under path-based formulation\n",
    "def path_cost_calculator(inptu_matrix, raw_data_dict, num_targets, num_views):\n",
    "    clus_dist = np.zeros((num_targets))\n",
    "    for i in range(num_views-1):\n",
    "        for m in range(num_targets):\n",
    "            curr_tar = inptu_matrix[m, i]\n",
    "            for n in range(num_targets):\n",
    "                if inptu_matrix[n, i+1] == curr_tar:\n",
    "                    curr_dist = raw_data_dict[(i+1,i+2)][m,n]\n",
    "                    clus_dist[m] += curr_dist\n",
    "    return sum(clus_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing the total distance of a cluster under clique-based formulation\n",
    "def cost_calculator(cluster, dic):\n",
    "    cost = 0\n",
    "    q = len(cluster)\n",
    "    n = len(cluster[0])\n",
    "    reshaped_cluster = cluster.T.reshape(cluster.shape[0]*cluster.shape[1])\n",
    "    \n",
    "    for i in range(q):\n",
    "        sub_cluster = np.array(np.where(reshaped_cluster==(i+1)))[0]\n",
    "        sub_cluster = np.array([sub_cluster[j]-j*q for j in range(n)])\n",
    "        for i in range(len(sub_cluster)): # number of views\n",
    "            for j in range(i+1, len(sub_cluster)):\n",
    "                cost += dic[(i+1, j+1)][int(sub_cluster[i])][int(sub_cluster[j])]\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate an arbitary True Clusering Matrix for all concensus.\n",
    "# User may alter dimensions for the methods:\n",
    "#    num_views -> number of sensors/stages\n",
    "#    num_targets -> number of targets\n",
    "def Generate_True_Clus_Matrix(num_targets, num_views):\n",
    "    true_clus_matrix = np.zeros((num_targets, num_views))\n",
    "\n",
    "    for i in range(num_views):\n",
    "        target_array = np.arange(1,num_targets+1)\n",
    "        for j in range(num_targets):\n",
    "            position = rand.randint(0,len(target_array)-1)\n",
    "            true_clus_matrix[j,i] = target_array[position]\n",
    "            target_array = np.delete(target_array, position)\n",
    "    \n",
    "    return true_clus_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Generate an arbitary True Position Matrix for all concensus based on the True Clustering Matrix, \n",
    "# under the scales that fit Uniorm(0,100).\n",
    "# Note:\n",
    "#    num_views and num_targets will have to match with True Clustering Matrix. \n",
    "def Generate_True_Position_Matrix(true_clus_matrix, num_targets, num_views):\n",
    "    true_position_matrix = np.zeros((num_targets, num_views))\n",
    "    max_scale = 100\n",
    "    base_scale = max_scale/num_targets\n",
    "    for i in range(num_targets):\n",
    "        for j in range(num_views):\n",
    "            curr_scale =  true_clus_matrix[i,j]\n",
    "            lower_bound = (curr_scale-1)*base_scale\n",
    "            upper_bound = curr_scale*base_scale\n",
    "\n",
    "            position = np.random.randint(lower_bound,upper_bound)\n",
    "            true_position_matrix[i,j] = position\n",
    "    return true_position_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Generate the Distance Matrix and Dictionary based on the Position Matrix.\n",
    "def Generate_Dist_Dict(position_matrix, num_targets, num_views):\n",
    "    dist_matrices = {}\n",
    "\n",
    "    for m in range(num_views):\n",
    "        for n in range(m+1, num_views):\n",
    "            dist_matrix = np.zeros((num_targets, num_targets))\n",
    "            for i in range(num_targets):\n",
    "                for j in range(num_targets):\n",
    "                    dist_matrix[i,j] = abs(position_matrix[i,m] - position_matrix[j,n])\n",
    "            dist_matrices[(m+1,n+1)] = dist_matrix\n",
    "            dist_matrices[(n+1,m+1)] = dist_matrix.T\n",
    "    \n",
    "    return dist_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add Noise to one sensor among all the sensors .\n",
    "# Note:\n",
    "#    Noise follows Normal Distribution with mean=0 and std=noise_scale*position.\n",
    "#    noise_scale should be [0,1]\n",
    "def Add_Sensor_Noise(position_matrix, noise_scale, num_targets, num_views):\n",
    "    noise_sensor = rand.randint(0,num_views-1)\n",
    "    noise_position_matrix = np.zeros((num_targets, num_views))\n",
    "\n",
    "    for i in range(num_targets):\n",
    "        for j in range(num_views):\n",
    "            if j != noise_sensor:\n",
    "                noise_position_matrix[i,j] = position_matrix[i,j]\n",
    "            else:\n",
    "                target_position = position_matrix[i, noise_sensor]\n",
    "                position_noise = int(np.random.normal(loc=0, scale=target_position*noise_scale))\n",
    "                noise_position_matrix[i,j] = target_position + position_noise\n",
    "                \n",
    "    return noise_position_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test generating True Position Matrix.\n",
    "def test_generate_true_clus_matrix(num_targets, num_views):\n",
    "    true_clus_matrix = Generate_True_Clus_Matrix(num_targets, num_views)\n",
    "    return true_clus_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test generating True Distance Matrix.\n",
    "def test_generate_true_pos_matrix(true_clus_matrix, num_targets, num_views):\n",
    "    true_position_matrix = Generate_True_Position_Matrix(true_clus_matrix, num_targets, num_views)\n",
    "    return true_position_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test generating Distance Dicctionary.\n",
    "def test_generate_dist_dict(position_matrix, num_targets, num_views):\n",
    "    dist_dict = Generate_Dist_Dict(position_matrix, num_targets, num_views)\n",
    "    return dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test adding Noise.\n",
    "def test_add_sensor_noise(true_position_matrix, noise_scale, num_targets, num_views):\n",
    "    noise_position_matrix = Add_Sensor_Noise(true_position_matrix, noise_scale, num_targets, num_views)\n",
    "    return noise_position_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match the first sensor clustering index with the true cluster matrix\n",
    "def match_clu_indicator(input_cluster, true_clus_matrix, num_targets, num_views):\n",
    "    match_dict = {}\n",
    "    for i in range(num_targets):\n",
    "        match_dict[input_cluster[i,0]] = true_clus_matrix[i,0]\n",
    "\n",
    "    output_matrix = np.zeros((num_targets, num_views))\n",
    "    for i in range(num_targets):\n",
    "        for j in range(num_views):\n",
    "            output_matrix[i,j] = match_dict[input_cluster[i,j]]\n",
    "    return output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to solve the Clique-based formulation single-source problem under noisy setting\n",
    "def clique_based_single_source_noise_test(noise_dist_dict, true_clus_matrix, num_targets, num_views):\n",
    "    clique_output_clu = ssa.RMSRA(noise_dist_dict, num_targets, num_views)\n",
    "    clique_output_matrix = match_clu_indicator(clique_output_clu, true_clus_matrix, num_targets, num_views)\n",
    "    return clique_output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to solve the Path-based formulation single-source problem under noisy setting\n",
    "def path_based_single_source_noise_test(noise_dist_dict, true_clus_matrix, num_targets, num_views):\n",
    "    path_output_clu = ssa.MSRA_p(noise_dist_dict, num_targets, num_views)\n",
    "    path_output_matrix = match_clu_indicator(path_output_clu, true_clus_matrix, num_targets, num_views)\n",
    "    return path_output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test Single Source Single Noise sensor\n",
    "# User can test a sequence of combination of dimensions.\n",
    "# User should alter the input dimension for the single source case to test\n",
    "#    num_targets_lower -> lower bound for the number of targets\n",
    "#    num_views_lower -> lower bound for the number of sensors/stages\n",
    "#    num_targets_upper -> upper bound for the number of targets\n",
    "#    num_views_upper -> upper bound for the number of sensors/stages\n",
    "#    noise_scales -> noise scaling vector, each scale should be in [0,1]\n",
    "# Clique-based/path-based formualtion can be tested based on function used\n",
    "#     un/comment to obtain the results user wanted.\n",
    "def single_source_noise_test(num_targets_lower, num_targets_upper, num_views_lower, num_views_upper, noise_scales):\n",
    "    noise_dict = {}\n",
    "\n",
    "    for s in noise_scales:   \n",
    "        noise_indicators = []\n",
    "        for i in range(num_targets_lower, num_targets_upper):\n",
    "            noise_indicator = []\n",
    "            for j in range(num_views_lower, num_views_upper):  \n",
    "                true_clus_matrix = Generate_True_Clus_Matrix(i, j)\n",
    "                true_position_matrix = Generate_True_Position_Matrix(true_clus_matrix, i, j)\n",
    "                true_dist_dict = Generate_Dist_Dict(true_position_matrix, i, j)\n",
    "\n",
    "                noise_position_matrix = Add_Sensor_Noise(true_position_matrix, s, i, j)\n",
    "                noise_dist_dict = Generate_Dist_Dict(noise_position_matrix, i, j)\n",
    "\n",
    "                # choose path-based or cliqeu-baed formulation\n",
    "                # path-based formulation\n",
    "                noise_output_clu = ssa.MSRA_p(noise_dist_dict, i, j)\n",
    "                \n",
    "                # clique-based formualtion\n",
    "                #noise_output_clu = ssa.RMSRA(noise_dist_dict, i, j)\n",
    "                \n",
    "                noise_output_matrix = match_clu_indicator(noise_output_clu, true_clus_matrix, i, j)\n",
    "\n",
    "                # choose cost computing series\n",
    "                # path-based cost computing series\n",
    "                true_cost = path_cost_calculator(true_clus_matrix, true_dist_dict, i, j)\n",
    "                noise_cost = path_cost_calculator(noise_output_matrix, true_dist_dict, i, j)\n",
    "                opt_gap = round((noise_cost - true_cost) / true_cost * 100, 3)\n",
    "                \n",
    "                # clique-based cost computing series\n",
    "                #true_cost = cost_calculator(true_clus_matrix, true_dist_dict)\n",
    "                #noise_cost = cost_calculator(noise_output_matrix, true_dist_dict)\n",
    "                #opt_gap = round((noise_cost - true_cost) / true_cost * 100, 3)\n",
    "\n",
    "                noise_indicator.append(opt_gap)\n",
    "            noise_indicators.append(noise_indicator)\n",
    "\n",
    "        if s not in noise_dict.keys():\n",
    "            noise_dict[s] = [noise_indicators]\n",
    "        else:\n",
    "            noise_dict[s].append(noise_indicators)\n",
    "    return noise_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to test Multi-source Noise sensor under CBSNMF\n",
    "# User can test a sequence of combination of dimensions.\n",
    "# User should alter the input dimension for the single source case to test\n",
    "#    num_targets_lower -> lower bound for the number of targets\n",
    "#    num_views_lower -> lower bound for the number of sensors/stages\n",
    "#    num_targets_upper -> upper bound for the number of targets\n",
    "#    num_views_upper -> upper bound for the number of sensors/stages\n",
    "#    noise_scales -> noise scaling vector, each scale should be in [0,1]\n",
    "# User may un/comment to choose similarity matrix and regularization matrix\n",
    "# User may output only with clusters, costs, alphas, and maximum iteration information \n",
    "# through corresponding dictionary\n",
    "def CBSNMF_noise_test(num_targets_lower, num_targets_upper, num_views_lower, num_views_upper, num_generated, noise_scales):\n",
    "    test_alphas = [1e-10,1e-9,1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2, 1e-1, 1, 10, 100, 1000]\n",
    "    test_iters = [10, 15, 20, 25, 50, 75, 100, 150, 200, 500, 750, 1000, 5000]\n",
    "    connected_reg = 0.1\n",
    "    unconeected_reg = 100\n",
    "\n",
    "    opt_noise_clus_dic = {}\n",
    "    opt_noise_costs_dic = {}\n",
    "    opt_noise_alphas_dic = {}\n",
    "    opt_noise_iters_dic = {}\n",
    "    opt_gap_dic = {}\n",
    "    for s in noise_scales:\n",
    "        opt_noise_clus = []\n",
    "        opt_noise_costs = []\n",
    "        opt_noise_alphas = []\n",
    "        opt_noise_iters = []\n",
    "        for i in range(num_targets_lower, num_targets_upper):\n",
    "            opt_noise_clu = []\n",
    "            opt_noise_cost = []\n",
    "            opt_noise_alpha = []\n",
    "            opt_noise_iter = []\n",
    "            for j in range(num_views_lower,num_views_upper):\n",
    "                true_clus_matrix = Generate_True_Clus_Matrix(i, j)\n",
    "                true_position_matrix = Generate_True_Position_Matrix(true_clus_matrix, i, j)\n",
    "                true_dist_dict = Generate_Dist_Dict(true_position_matrix, i, j)\n",
    "\n",
    "                single_source_outputs = {}\n",
    "                single_source_matrixs = {}\n",
    "                for k in range(num_generated):\n",
    "                    noise_position_matrix = Add_Sensor_Noise(true_position_matrix, s, i, j)\n",
    "                    noise_dist_dict = Generate_Dist_Dict(noise_position_matrix, i, j)\n",
    "                    noise_output_clu = ssa.RMSRA(noise_dist_dict, i, j)\n",
    "                    \n",
    "                    noise_output_matrix = match_clu_indicator(noise_output_clu, true_clus_matrix, i, j)\n",
    "\n",
    "                    single_source_outputs[k] = noise_output_clu\n",
    "                    single_source_matrixs[k] = noise_output_matrix\n",
    "\n",
    "                optimal_con_cost = 999999\n",
    "                for a in test_alphas:\n",
    "                    for max_iter in test_iters:\n",
    "                        for k in range(5):\n",
    "                            #indicator_matrix = cbsnmf.get_norm_indicator_matrix(single_source_outputs, i, j, num_generated)\n",
    "                            indicator_matrix = cbsnmf.get_scale_indicator_matrix(single_source_outputs, i, j)\n",
    "                            #indicator_matrix = cbsnmf.density_indicator_matrix(single_source_outputs, i, j, num_generated)\n",
    "\n",
    "                            #g = cbsnmf.get_reg_matrix(indicator_matrix, connected_reg, unconeected_reg)\n",
    "                            g = cbsnmf.get_scale_reg_matrix(single_source_outputs, i, j)\n",
    "\n",
    "                            u = cbsnmf.matrix_fact(indicator_matrix, g, a, max_iter, i, j)\n",
    "                            cbsnmf_result = cbsnmf.get_concensus_matrix(u, i, j)\n",
    "                            cbsnmf_matrix = match_clu_indicator(cbsnmf_result, true_clus_matrix, i, j)\n",
    "\n",
    "                            concensus_cost = cost_calculator(cbsnmf_matrix, true_dist_dict)\n",
    "                            if concensus_cost < optimal_con_cost:\n",
    "                                optimal_clu = cbsnmf_matrix\n",
    "                                optimal_con_cost = concensus_cost\n",
    "                                optimal_alpha = a\n",
    "                                optimal_iter = max_iter\n",
    "                                \n",
    "                opt_noise_clu.append(optimal_clu)\n",
    "                opt_noise_cost.append(optimal_con_cost)\n",
    "                opt_noise_alpha.append(optimal_alpha)\n",
    "                opt_noise_iter.append(max_iter)\n",
    "            \n",
    "                true_cost = cost_calculator(true_clus_matrix, true_dist_dict)\n",
    "                opt_con_cost = cost_calculator(optimal_clu, true_dist_dict)\n",
    "                opt_gap = round((opt_con_cost - true_cost) / true_cost * 100, 3)\n",
    "                opt_gap_dic[(s,i,j)] = (optimal_alpha, max_iter, opt_gap, optimal_clu)\n",
    "            \n",
    "            opt_noise_clus.append(opt_noise_clu)\n",
    "            opt_noise_costs.append(opt_noise_cost)\n",
    "            opt_noise_alphas.append(opt_noise_alpha)\n",
    "            opt_noise_iters.append(opt_noise_iter)\n",
    "\n",
    "        \n",
    "        if s not in opt_noise_clus_dic.keys():\n",
    "            opt_noise_clus_dic[s] = [opt_noise_clus]\n",
    "        else:\n",
    "            opt_noise_clus_dic[s].append(opt_noise_clus)\n",
    "        \n",
    "        if s not in opt_noise_costs_dic.keys():\n",
    "            opt_noise_costs_dic[s] = [opt_noise_costs]\n",
    "        else:\n",
    "            opt_noise_costs_dic[s].append(opt_noise_costs)\n",
    "        \n",
    "        \n",
    "        if s not in opt_noise_alphas_dic.keys():\n",
    "            opt_noise_alphas_dic[s] = [opt_noise_alphas]\n",
    "        else:\n",
    "            opt_noise_alphas_dic[s].append(opt_noise_alphas)\n",
    "        \n",
    "        if s not in opt_noise_iters_dic.keys():\n",
    "            opt_noise_iters_dic[s] = [opt_noise_iters]\n",
    "        else:\n",
    "            opt_noise_iters_dic[s].append(opt_noise_iters)\n",
    "            \n",
    "    return opt_gap_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to test Multi-source Noise sensor under LMVC\n",
    "# User can test a sequence of combination of dimensions.\n",
    "# User should alter the input dimension for the single source case to test\n",
    "#    num_targets_lower -> lower bound for the number of targets\n",
    "#    num_views_lower -> lower bound for the number of sensors/stages\n",
    "#    num_targets_upper -> upper bound for the number of targets\n",
    "#    num_views_upper -> upper bound for the number of sensors/stages\n",
    "#    noise_scales -> noise scaling vector, each scale should be in [0,1]\n",
    "def LMVC_noise_test(num_targets_lower, num_targets_upper, num_views_lower, num_views_upper, num_generated, noise_scales):\n",
    "    noise_dict = {}\n",
    "    opt_gap_dic = {}\n",
    "    for s in noise_scales:\n",
    "        noise_indicators = []\n",
    "        for i in range(num_targets_lower, num_targets_upper):\n",
    "            noise_indicator = []\n",
    "            for j in range(num_views_lower,num_views_upper):\n",
    "                true_clus_matrix = Generate_True_Clus_Matrix(i, j)\n",
    "                true_position_matrix = Generate_True_Position_Matrix(true_clus_matrix, i, j)\n",
    "                true_dist_dict = Generate_Dist_Dict(true_position_matrix, i, j)\n",
    "\n",
    "                single_source_outputs = {}\n",
    "                single_source_matrixs = {}\n",
    "                LMVC_inputs = {}\n",
    "                \n",
    "                for k in range(num_generated):\n",
    "                    noise_position_matrix = Add_Sensor_Noise(true_position_matrix, s, i, j)\n",
    "                    noise_dist_dict = Generate_Dist_Dict(noise_position_matrix, i, j)\n",
    "                    noise_output_clu = ssa.RMSRA(noise_dist_dict, i, j)\n",
    "                    \n",
    "                    noise_output_matrix = match_clu_indicator(noise_output_clu, true_clus_matrix, i, j)\n",
    "\n",
    "                    single_source_outputs[k] = noise_output_clu\n",
    "                    single_source_matrixs[k] = noise_output_matrix\n",
    "\n",
    "                    LMVC_input = np.ones((i, j))\n",
    "                    for p in range(i):\n",
    "                        for q in range(i):\n",
    "                            for r in range(j):\n",
    "                                if noise_output_clu[q][r] == p:\n",
    "                                    LMVC_input[p][r] = q\n",
    "                    LMVC_input = LMVC_input.astype(int)\n",
    "                    LMVC_inputs[k] = LMVC_input\n",
    "                    \n",
    "                cross_domain_source = lmvc.Data(j, i, LMVC_inputs)\n",
    "                cluster = cross_domain_source.process()\n",
    "                cluster = np.array(cluster)\n",
    "                cluster_rev = np.ones([i, j])\n",
    "                for p in range(len(cluster_rev)):\n",
    "                    for q in range(len(cluster_rev[0])):\n",
    "                        row_num = cluster[p][q]\n",
    "                        col_num = q\n",
    "                        cluster_rev[row_num,col_num] = p\n",
    "                cluster_rev = cluster_rev.astype(int)\n",
    "                cluster_matrix = match_clu_indicator(cluster_rev, true_clus_matrix, i, j)\n",
    "\n",
    "                true_cost = cost_calculator(true_clus_matrix, true_dist_dict)\n",
    "                opt_con_cost = cost_calculator(cluster_matrix, true_dist_dict)\n",
    "                opt_gap = round((opt_con_cost - true_cost) / true_cost * 100, 3)\n",
    "                opt_gap_dic[(s,i,j)] = (opt_gap, cluster_matrix)\n",
    "\n",
    "                noise_indicator.append(opt_gap)\n",
    "            noise_indicators.append(noise_indicator)\n",
    "            \n",
    "        if s not in noise_dict.keys():\n",
    "            noise_dict[s] = [noise_indicators]\n",
    "        else:\n",
    "            noise_dict[s].append(noise_indicators)\n",
    "    return opt_gap_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    num_targets = 5\n",
    "    num_views = 6\n",
    "    noise_scale = 0.1\n",
    "\n",
    "    # generate gound true cluster, position matrix and distance dictionary \n",
    "    true_clus_matrix = test_generate_true_clus_matrix(num_targets, num_views)\n",
    "    true_position_matrix = test_generate_true_pos_matrix(true_clus_matrix, num_targets, num_views) \n",
    "    true_dist_dict = test_generate_dist_dict(true_position_matrix, num_targets, num_views)\n",
    "\n",
    "    # generate noise position matrix and distance dictionary \n",
    "    noise_position_matrix = test_add_sensor_noise(true_position_matrix, noise_scale, num_targets, num_views)\n",
    "    noise_dist_dict = test_generate_dist_dict(noise_position_matrix, num_targets, num_views)\n",
    "\n",
    "    #print('True Posittion Matrix:')\n",
    "    #print(true_position_matrix)\n",
    "    #print('Noise Posittion Matrix:')\n",
    "    #print(noise_position_matrix)\n",
    "    #print('Matrix Difference:')\n",
    "    #print(noise_position_matrix - true_position_matrix)\n",
    "    \n",
    "    # solve the single-source noise problem under clique-based formulation and compare the optimality gaps\n",
    "    clique_output_matrix = clique_based_single_source_noise_test(noise_dist_dict, true_clus_matrix, num_targets, num_views)\n",
    "    true_cost = cost_calculator(true_clus_matrix, true_dist_dict)\n",
    "    noise_cost = cost_calculator(clique_output_matrix, true_dist_dict)\n",
    "    opt_gap = round((noise_cost - true_cost) / true_cost * 100, 3)\n",
    "\n",
    "    #print('Clique-based Formulation')\n",
    "    #print(\"True Clustering Distance:\")\n",
    "    #print(true_cost)\n",
    "    #print(\"Noise Clustering Distance:\")\n",
    "    #print(noise_cost)\n",
    "    #print('Optimality Gap: ')\n",
    "    #print(str(opt_gap) + '%')\n",
    "    \n",
    "    # solve the single-source noise problem under path-based formaltion and compare the optimality gaps\n",
    "    path_output_matrix = path_based_single_source_noise_test(noise_dist_dict, true_clus_matrix, num_targets, num_views)\n",
    "    true_cost = path_cost_calculator(true_clus_matrix, true_dist_dict, num_targets, num_views)\n",
    "    noise_cost = path_cost_calculator(path_output_matrix, true_dist_dict, num_targets, num_views)\n",
    "    opt_gap = round((noise_cost - true_cost) / true_cost * 100, 3)\n",
    "    \n",
    "    #print('Path-based Formulation')\n",
    "    #print(\"True Clustering Distance:\")\n",
    "    #print(true_cost)\n",
    "    #print(\"Noise Clustering Distance:\")\n",
    "    #print(noise_cost)\n",
    "    #print('Optimality Gap: ')\n",
    "    #print(str(opt_gap) + '%')\n",
    "    \n",
    "    # input variables for single-source and multi-source noise testing\n",
    "    num_targets_lower = 3\n",
    "    num_targets_upper = 11\n",
    "    num_views_lower = 3\n",
    "    num_views_upper = 21\n",
    "    num_generated = 5\n",
    "    noise_scales = [s/20 for s in range(20)]\n",
    "    \n",
    "    # test on the single source noise based on different noise scaling\n",
    "    single_noise = single_source_noise_test(num_targets_lower, num_targets_upper, num_views_lower, num_views_upper, noise_scales)\n",
    "    #print(single_noise)\n",
    "    \n",
    "    # test on the multi-source noise under LMVC based on different noise scaling\n",
    "    lmvc_noise = LMVC_noise_test(num_targets_lower, num_targets_upper, num_views_lower, num_views_upper, num_generated, noise_scales)\n",
    "    #print(lmvc_noise)\n",
    "    \n",
    "    # test on the multi-source noise under CBSNMF based on different noise scaling\n",
    "    cbsnmf_noise = CBSNMF_noise_test(num_targets_lower, num_targets_upper, num_views_lower, num_views_upper, num_generated, noise_scales)\n",
    "    #print(cbsnmf_noise)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
